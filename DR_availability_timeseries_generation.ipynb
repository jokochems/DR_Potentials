{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Availability time series generation\n",
    "\n",
    "**Purpose and background**: This notebook serves to generate resp. put together \n",
    "availability time series for demand response potentials which are used \n",
    "in the clustering process to calculate weighted average values resp. \n",
    "overall availability time series per demand response cluster. \n",
    "The latter is used in power market model runs for simulating demand response.\n",
    "\n",
    "## Method applied\n",
    "In the following, a brief description of the method applied is given for the sake of replicability.\n",
    "The main literature sources used are [Gils (2015)](http://dx.doi.org/10.18419/opus-6888), \n",
    "[Steuer (2017)](http://dx.doi.org/10.18419/opus-9181) and \n",
    "[Ladwig (2018)](https://nbn-resolving.org/urn:nbn:de:bsz:14-qucosa-236074), \n",
    "since these publications offer the most detailed information on load profiles and availability\n",
    "from the ones that were evaluated within the demand response potential meta-analysis.\n",
    "The actual generation of demand response availability time series was the topic of three bachelor\n",
    "theses. The bachelor theses combine different sources from the literature and introduce some further\n",
    "assumptions to account for shortcomings in the literature. The approaches used in detail \n",
    "differ per sector and demand response category. The bachelor theses results are build upon \n",
    "in this notebook. Detailed method descriptions can be found within these theses and the respective \n",
    "supplementary material.\n",
    "\n",
    "Bibliographical information for the bachelor theses:\n",
    "* _Stange, Rico (2019): Ermittlung von Kosten und Zeitverfügbarkeiten einer Flexibilisierung der \n",
    "Stromnachfrage, Freie wissenschaftliche Arbeit zur Erlangung des Grades eines Bachelor of Science \n",
    "am Fachgebiet Energie- und Ressourcenmanagement der TU Berlin._ \n",
    "__*Focus: household sector*__\n",
    "* _Odeh, Jonas (2019): Ermittlung von Kosten und Zeitverfügbarkeiten für die Flexibilisierung \n",
    "von Stromnachfragen im GHD-Sektor, Freie wissenschaftliche Arbeit zur Erlangung des Grades eines \n",
    "Bachelor of Science am Fachgebiet Energie- und Ressourcenmanagement der TU Berlin._\n",
    "__*Focus: trade, commerce and services*__\n",
    "* _Benz, Fabian (2019): Ermittlung von Kosten und Zeitverfügbarkeit für flexible Stromnachfragen \n",
    "in der Industrie in Deutschland, Freie wissenschaftliche Arbeit zur Erlangung des Grades eines \n",
    "Bachelor of Science am Fachgebiet Energie- und Ressourcenmanagement der TU Berlin._\n",
    "__*Focus: industry sector*__\n",
    "\n",
    "### Creation of load profiles per demand response category\n",
    "Load profiles on the level of demand response categories serve as the basis for creating\n",
    "demand response availability time series. The load profiles are derived from the literature and\n",
    "needed since demand response limits can be derived from these.\n",
    "\n",
    "### Creation of demand response availability time series\n",
    "Demand response is limited by the following rules (see e.g. Steurer 2017, p. 48):\n",
    "* Downwards shifts (positive demand response potential) must be smaller or equal to the difference \n",
    "of actual load and minimum load:\n",
    "$$ P_{down}(t) \\leq P(t) - P_{min}(t) $$ \n",
    "* Upwards shifts (negative demand response potential) must be smaller or equal to the difference \n",
    "of maximum load and actual load:\n",
    "$$ P_{up}(t) \\leq P_{max}(t) - P(t) $$\n",
    "\n",
    "Hence, if there is no minimum load, the load profile marks the overall limit for possible demand \n",
    "reductions. In many cases, it is either possible to increase demand up to the overall maximum power \n",
    "output or the load profile in a way serves binding here, as well. This is the case e.g. for \n",
    "appliances with an implicit thermal storage, such as electrical heating.\n",
    "\n",
    "**Rules for determining minimum and maximum loads**:\n",
    "\n",
    "| demand response category | minimum load | maximum load |\n",
    "| ---- | ---- | ---- |\n",
    "| household and tcs appliances | none | overall max. demand or max. demand for day / season |\n",
    "| thermal appliances | none | max. demand per day |\n",
    "| industrial processes | process-specific | process-specific |\n",
    "\n",
    "_NOTE: These rules only apply for short-term load shifts resp. load shedding._\n",
    "\n",
    "**Demand response availability factors**\n",
    "\n",
    "To account for availability, an availibility factor in upwards resp. downwards shifiting\n",
    "direction is introduced. This value is normalized, i.e. $ \\in [0;1] $. If this isn't already\n",
    "the case in the baseline, the current maximum value ($ < 1 $) is used as a scaling factor (see\n",
    "bachelor theses for details).\n",
    "\n",
    "Interpretation:\n",
    "* 0 denotes the time(s) of the year when none of the maximum demand response potential is available.\n",
    "* 1 denotes the time(s) of the year when the maximum demand response potential is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Parameter settings\n",
    "* Set path folder and filenames for inputs and outputs.\n",
    "* Define lists with columns to keep (i.e. decide which ones to drop).\n",
    "* Define two dicts mapping weekdays resp. months names (str) to the int output of pd.DateTimeIndex:\n",
    "    * *days_dict*: 0 = Monday .. 6 = Sunday\n",
    "    * *months_dict*: 0 = January .. 12 = December\n",
    "* Set some boolean control parameters for the workflow:\n",
    "    * _drop_leap_day_: If True, the leap day will be dropped making leap years comparable to\n",
    "    regular ones. _NOTE: The weekly pattern will be destroyed by simply dropping the leap day. \n",
    "    Another possibility would be to create a synthetic year by simply dropping the first or last\n",
    "    day of the year._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_folder_hoho = \"./inputs/availability_hoho/\"\n",
    "path_folder_tcs = \"./inputs/availability_tcs/\"\n",
    "path_folder_ind = \"./inputs/availability_ind/\"\n",
    "path_folder_out = \"./out/availability/\"\n",
    "filename_out = \"availability_timeseries.xlsx\"\n",
    "\n",
    "filename_hoho_appliances = \"Verfuegbarkeit_Weisse_Ware_bearbeitet.xlsm\"\n",
    "filename_hoho_heating = \"Verfuegbarkeit_Waermeanwendungen_bearbeitet.xlsm\"\n",
    "\n",
    "filename_tcs_Gil15 = \"Gils_2015_berarbeitet.xlsx\"\n",
    "filename_tcs_Gre09 = \"Grein_2009_bearbeitet.xlsx\"\n",
    "filename_tcs_Lad18 = \"Ladwig_2018_bearbeitet.xlsx\"\n",
    "filename_tcs_Ste17 = \"Steurer_2017_bearbeitet.xlsx\"\n",
    "\n",
    "filename_ind = \"Zeitverfuegbarkeit2_bearbeitet.xlsx\"\n",
    "filename_ind_add = \"Zeitverfuegbarkeit1_bearbeitet.xlsx\"\n",
    "\n",
    "cols_hoho_appliances = ['Monat', 'Gerundete Temperatur', 'Stunden des Jahres',\n",
    "                        'Stunden des Tages', 'Wochentag', 'Jahreszeit',\n",
    "                        'Lastzuschaltung KGR normiert', 'Lastabschaltung KGR',\n",
    "                        'Lastzuschaltung WM normiert', 'Lastabschaltung WM',\n",
    "                        'Lastzuschaltung WT normiert', 'Lastabschaltung WT',\n",
    "                        'Lastzuschaltung GS normiert', 'Lastabschaltung GS']\n",
    "\n",
    "cols_hoho_heating = ['Monat', 'äquivalente Tagesmitteltemperatur',\n",
    "                     'Kühlbedarf', 'Heizbedarf', 'Gerundete Temperatur',\n",
    "                     'Stunden des Jahres ', 'Stunden des Tages', 'Wochentag', 'Jahreszeit',\n",
    "                     'Lastabschaltung NH normiert', 'Lastzuschaltung NH normiert',\n",
    "                     'Lastabschaltung WP normiert', 'Lastzuschaltung WP normiert',\n",
    "                     'Lastabschaltung UP', 'Lastabschaltung RK', 'Lastzuschaltung RK',\n",
    "                     'Lastabschaltung WW Tag', 'Lastzuschaltung WW normiert Tag']\n",
    "\n",
    "cols_tcs_Gil15 = ['Gerundete Temperatur', 'Heizbedarf', 'äquivalente Tagesmitteltemperatur', \n",
    "                  'Stunden des Jahres ', 'Uhrzeit des Tages', 'Wochentag', 'Feiertag', \n",
    "                  'Jahreszeit', 'Lastzuschaltung LÜ normiert', 'Lastabschaltung LÜ normiert',\n",
    "                  'Lastzuschaltung WVP normiert', 'Lastabschaltung WVP normiert']\n",
    "\n",
    "cols_tcs_Gre09 = ['Monat', 'Gerundete Temperatur', 'Heizbedarf',\n",
    "                  'äquivalente Tagesmitteltemperatur', 'Stunden des Jahres ',\n",
    "                  'Uhrzeit des Tages', 'Wochentag', 'Feiertag', 'Jahreszeit',\n",
    "                  'Lastzuschaltung KGR normiert', 'Lastabschaltung KGR normiert', \n",
    "                  'Lastzuschaltung KÜ normiert', 'Lastabschaltung KÜ normiert']\n",
    "\n",
    "cols_tcs_Lad18 = ['Gerundete Temperatur', 'Heizbedarf', 'äquivalente Tagesmitteltemperatur', \n",
    "                  'Stunden des Jahres ', 'Uhrzeit des Tages', 'Wochentag', 'Feiertag', \n",
    "                  'Jahreszeit', 'Lastzuschaltung KA normiert', 'Lastabschaltung KA normiert']\n",
    "\n",
    "cols_tcs_Ste17 = ['Gerundete Temperatur', 'Heizbedarf', 'äquivalente Tagesmitteltemperatur', \n",
    "                  'Stunden des Jahres ', 'Uhrzeit des Tages', 'Wochentag', 'Feiertag', \n",
    "                  'Jahreszeit', 'Lastzuschaltung EH normiert', 'Lastabschaltung EH normiert',\n",
    "                  'Lastzuschaltung WP normiert', 'Lastabschaltung WP normiert',\n",
    "                  'Lastzuschaltung WW normiert', 'Lastabschaltung WW normiert']\n",
    "\n",
    "days_dict = {0: \"Montag\",\n",
    "             1: \"Dienstag\",\n",
    "             2: \"Mittwoch\",\n",
    "             3: \"Donnerstag\",\n",
    "             4: \"Freitag\",\n",
    "             5: \"Samstag\",\n",
    "             6: \"Sonntag\"}\n",
    "\n",
    "months_dict = {1: \"Januar\",\n",
    "               2: \"Februar\",\n",
    "               3: \"März\",\n",
    "               4: \"April\",\n",
    "               5: \"Mai\",\n",
    "               6: \"Juni\",\n",
    "               7: \"Juli\",\n",
    "               8: \"August\",\n",
    "               9: \"September\",\n",
    "               10: \"Oktober\",\n",
    "               11: \"November\",\n",
    "               12: \"Dezember\"}\n",
    "\n",
    "drop_leap_day = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read in data\n",
    "Read in data for the different sectors:\n",
    "* hoho: divided by appliances and heating related consumers\n",
    "* tcs: divided by studies\n",
    "* ind: divided by processes with varying potentials and those with constant potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hoho_appliances = pd.read_excel(path_folder_hoho+filename_hoho_appliances,\n",
    "                                sheet_name=\"Datengrundlage\", \n",
    "                                skiprows=5, header=0, index_col=1)\n",
    "\n",
    "hoho_heating = pd.read_excel(path_folder_hoho+filename_hoho_heating,\n",
    "                             sheet_name=\"Datengrundlage\", \n",
    "                             skiprows=5, header=0, index_col=2)\n",
    "\n",
    "tcs_Gil15 = pd.read_excel(path_folder_tcs+filename_tcs_Gil15,\n",
    "                          sheet_name=\"Zeitreihen_Lastverschiebung\",\n",
    "                          skiprows=5, header=0, index_col=1)\n",
    "\n",
    "tcs_Gre09 = pd.read_excel(path_folder_tcs+filename_tcs_Gre09,\n",
    "                          sheet_name=\"Zeitreihen_Lastverschiebung\",\n",
    "                          skiprows=5, header=0, index_col=1)\n",
    "\n",
    "tcs_Lad18 = pd.read_excel(path_folder_tcs+filename_tcs_Lad18,\n",
    "                          sheet_name=\"Zeitreihen_Lastverschiebung\",\n",
    "                          skiprows=5, header=0, index_col=1)\n",
    "\n",
    "tcs_Ste17 = pd.read_excel(path_folder_tcs+filename_tcs_Ste17,\n",
    "                          sheet_name=\"Zeitreihen_Lastverschiebung\",\n",
    "                          skiprows=5, header=0, index_col=1)\n",
    "\n",
    "ind_varying = pd.read_excel(path_folder_ind+filename_ind,\n",
    "                            sheet_name=\"Verläufe mit Abhängigkeiten\",\n",
    "                            usecols=\"A:G\", header=0) \n",
    "\n",
    "ind_constant = pd.read_excel(path_folder_ind+filename_ind,\n",
    "                            sheet_name=\"konstante Verläufe\",\n",
    "                            header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare data and combine to overall data set\n",
    "* Delete columns not needed anymore resp. keep only the columns of interest.\n",
    "* Combine all availability time series to overall DataFrames.\n",
    "    * Remove duplicate columns and set index dtype to str.\n",
    "    * Separate positive and negative load shift availability.\n",
    "    * Store the DataFrames in a dict and use keys for creating Excel sheet names (see below.)\n",
    "* For the industry sector only: add calendar and temperature information\n",
    "(timestamp, weekday, month etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data (delete columns not needed and adjust index dtype)\n",
    "hoho_appliances = hoho_appliances[cols_hoho_appliances]\n",
    "hoho_heating = hoho_heating[cols_hoho_heating]\n",
    "\n",
    "tcs_Gil15 = tcs_Gil15[cols_tcs_Gil15]\n",
    "tcs_Gre09 = tcs_Gre09[cols_tcs_Gre09]\n",
    "tcs_Lad18 = tcs_Lad18[cols_tcs_Lad18]\n",
    "tcs_Ste17 = tcs_Ste17[cols_tcs_Ste17]\n",
    "\n",
    "# Convert index to DatetimeIndex\n",
    "# Index can be used for all sectors / DataFrames due to equal indexing\n",
    "new_index = hoho_appliances.index.astype(str)\n",
    "new_index = pd.to_datetime(hoho_appliances.index.values, format='%Y%m%d%H', errors='ignore')\n",
    "\n",
    "hoho_appliances = hoho_appliances.set_index(new_index)\n",
    "hoho_heating = hoho_heating.set_index(new_index)\n",
    "\n",
    "tcs_Gil15 = tcs_Gil15.set_index(new_index)\n",
    "tcs_Gre09 = tcs_Gre09.set_index(new_index)\n",
    "tcs_Lad18 = tcs_Lad18.set_index(new_index)\n",
    "tcs_Ste17 = tcs_Ste17.set_index(new_index)\n",
    "\n",
    "ind_varying = ind_varying.set_index(new_index)\n",
    "ind_constant = ind_constant.set_index(new_index)\n",
    "\n",
    "# display(hoho_appliances.head())\n",
    "# display(hoho_heating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Combine the data\n",
    "hoho_combined = pd.concat([hoho_appliances, hoho_heating], axis=1, sort=False)\n",
    "hoho_combined = hoho_combined.loc[:, ~hoho_combined.columns.duplicated()]\n",
    "\n",
    "tcs_combined = pd.concat([tcs_Gil15, tcs_Gre09, tcs_Lad18, tcs_Ste17], axis=1, sort=False)\n",
    "tcs_combined = tcs_combined.loc[:, ~tcs_combined.columns.duplicated()]\n",
    "\n",
    "ind_combined = pd.concat([ind_varying, ind_constant], axis=1, sort=False)\n",
    "ind_combined = ind_combined.loc[:, ~ind_combined.columns.duplicated()]\n",
    "\n",
    "# Add some calendar and temperature information for the industry sector\n",
    "ind_combined[\"Wochentag\"] = ind_combined.index.weekday.map(days_dict)\n",
    "ind_combined[\"Monat\"] = ind_combined.index.month.map(months_dict)\n",
    "ind_combined[\"Gerundete Temperatur\"] = hoho_combined[\"Gerundete Temperatur\"]\n",
    "ind_combined[\"Tagesmitteltemperatur\"] = pd.read_excel(path_folder_ind+filename_ind_add,\n",
    "                                                      sheet_name=\"RZM\", usecols=\"D\", header=0)\n",
    "\n",
    "# Filter out the leap day (if this is necessary)\n",
    "# Problem here: Weekly pattern is destroyed for the week with the leap day\n",
    "if drop_leap_day:\n",
    "    mask = (hoho_combined.index < \"2012-02-29 00:00\") | (hoho_combined.index > \"2012-02-29 23:00\")\n",
    "    hoho_combined = hoho_combined[mask]\n",
    "    tcs_combined = tcs_combined[mask]\n",
    "    ind_combined = ind_combined[mask]\n",
    "    # Same but for str as index dtype\n",
    "    # hoho_combined = hoho_combined[~hoho_combined.index.str.contains(\"0229\")]\n",
    "    \n",
    "hoho_combined_pos = hoho_combined.filter(regex=\"Lastabschaltung\")\n",
    "hoho_combined_neg = hoho_combined.filter(regex=\"Lastzuschaltung\")\n",
    "tcs_combined_pos = tcs_combined.filter(regex=\"Lastabschaltung\")\n",
    "tcs_combined_neg = tcs_combined.filter(regex=\"Lastzuschaltung\")\n",
    "ind_combined_pos = ind_combined.filter(regex=\"LRP\")\n",
    "ind_combined_neg = ind_combined.filter(regex=\"LZP\")\n",
    "\n",
    "# Dictionary to store the availability DataFrames\n",
    "dict_availability = {\"hoho_pos\": hoho_combined_pos,\n",
    "                     \"hoho_neg\": hoho_combined_neg,\n",
    "                     \"tcs_pos\": tcs_combined_pos,\n",
    "                     \"tcs_neg\": tcs_combined_neg,\n",
    "                     \"ind_pos\": ind_combined_pos,\n",
    "                     \"ind_neg\": ind_combined_neg}\n",
    "\n",
    "# display(hoho_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Store the output to Excel\n",
    "\n",
    "Store every DataFrame on a separate Excel sheet and use the dict keys from above as sheet names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(path_folder_out+filename_out, engine = \"xlsxwriter\")\n",
    "\n",
    "for k, v in dict_availability.items():\n",
    "\n",
    "    v.to_excel(writer, sheet_name = k)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
